# -*- coding: utf-8 -*-
"""CNN AI Safety

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rBvVWIbq8-oytHMUuKcZoJImePeA9HsL
"""

from google.colab import drive
drive.mount('/content/drive')     #my google drive has the file

# Commented out IPython magic to ensure Python compatibility.
# %config Completer.use_jedi = False
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import seaborn as sns
import cv2
import os
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader, random_split
from skimage import color
import scipy.misc
import PIL
from sklearn.utils import resample
from sklearn.metrics import confusion_matrix

#different categories
categories = ['Bicycle', 'Bus', 'Car', 'Motorcycle', 'NonVehicles', 'Taxi', 'Truck', 'Van']
img_size = 64


# Compose the transformation pipeline
transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor(),  # image to tensor
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])

batch_size = 16

def imshow(img):   #function to unnormalize in order to show the images in the later code
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

data = torchvision.datasets.ImageFolder('/content/drive/MyDrive/vehicle_classification', transform=transform)
#8:2 split for train and test
train_size = int(0.80 * len(data))
test_size = len(data) - train_size
train_data, test_data = random_split(data, [train_size, test_size])

# dataloaders to training and testing data
batch_size = 16
train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)

print(len(test_data)) #just making sure the split happened
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)

class CNN(nn.Module): #cnn model itself
    def __init__(self,num_classes=8):
        super().__init__()

        self.conv1 = nn.Conv2d(3, 8, 3, padding=1)
        self.pool1 = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)
        self.pool2 = nn.MaxPool2d(2, 2)

        self.fc1 = nn.Linear(4096 , 64)
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 8)

    def forward(self, x):
        x = self.pool1(F.relu(self.conv1(x)))
        x = self.pool2(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1)  # flatten all dimensions except batch
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

net = CNN(num_classes=8)
criterion = nn.CrossEntropyLoss()   #using cross entropy loss for our error
optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)  #optimizer helps with the weight updating

for epoch in range(5):
    print("epoch", epoch + 1)
    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        inputs, labels = data

        # Check if any label is out of bounds
        if (labels < 0).any() or (labels >= len(categories)).any():
            continue  # Skip this batch

        optimizer.zero_grad()

        outputs = net(inputs.float())

        # Print the outputs for debugging
        #print("Outputs:", outputs)

        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        if i % 50 == 49:
            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')
            running_loss = 0.0
print("finished")

from matplotlib.axis import YAxis
PATH = './CNN.pth'    #saves the model so we can refer to it
torch.save(net.state_dict(), PATH)

dataiter = iter(test_loader)
images, labels = next(dataiter)

# print images
imshow(torchvision.utils.make_grid(images))   #prints images from test data
print('GroundTruth: ', ' '.join(f'{categories[labels[j]]}' for j in range(3)))

net = CNN()
net.load_state_dict(torch.load(PATH))  #using the previous model we trained

outputs = net(images)

_, predicted = torch.max(outputs, 1)

print('Predicted: ', ' '.join(f'{categories[predicted[j]]}'      #printing out the predictions of the images we gave
                              for j in range(3)))

correct = 0
total = 0
# since we're not training, we don't need to calculate the gradients for our outputs
with torch.no_grad():
    for data in test_loader:   #for each image in testloader, we find the predicted value
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f'Accuracy of the network: {100 * correct // total} %')  #the actual acccuracy of the cnn